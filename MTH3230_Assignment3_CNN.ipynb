{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Connor1208/git-basics-activity/blob/main/MTH3230_Assignment3_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97uHp4GJp1q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import Tensor\n",
        "from typing import List\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "TICKER = \"AAPL\"\n",
        "PERIOD = \"max\"\n",
        "WINDOW = 30 # lookback days for features\n",
        "BATCH = 64\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 1e-3\n",
        "HIDDEN = [128, 64] # MLP hidden sizes\n",
        "P_DROPOUT = 0.1\n",
        "ACTIVATION_FN = nn.ReLU\n",
        "CRITERION = nn.MSELoss\n",
        "OPTIMIZER = torch.optim.Adam\n",
        "PATIENCE = 5\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Create a DataFrame to display model params\n",
        "params = pd.DataFrame({\n",
        "    'Parameter': ['Input Window Size', 'Input Data Range', 'Hidden Layers',\n",
        "                'Activation Function', 'Optimizer', 'Dropout P', 'Eval Metric',\n",
        "                'Batch Size', 'Learning Rate', 'Patience'],\n",
        "    'Value': [WINDOW, PERIOD, HIDDEN, ACTIVATION_FN, OPTIMIZER, P_DROPOUT, CRITERION,\n",
        "            BATCH, LEARNING_RATE, PATIENCE]\n",
        "})\n",
        "\n",
        "display(params)\n",
        "\n",
        "\n",
        "\n",
        "# Daily open/high/low/close/volume for Apple (AAPL), 1980–present.\n",
        "# Forecasting task: Predict next-day closing price or return.\n",
        "tick = yf.Ticker(TICKER)\n",
        "hist = tick.history(period=PERIOD)\n",
        "display(hist.tail())\n",
        "\n",
        "\n",
        "\n",
        "# The input data that we want to use to predict tmr's closing value\n",
        "X = pd.DataFrame(index=hist.index)\n",
        "X[\"Close\"] = hist[\"Close\"]\n",
        "X[\"Volume\"] = hist[\"Volume\"]\n",
        "X[\"rolling_mean_3\"] = hist[\"Close\"].rolling(3).mean()\n",
        "X[\"rolling_mean_14\"] = hist[\"Close\"].rolling(14).mean()\n",
        "X[\"rolling_std_3\"] = hist[\"Close\"].rolling(3).std()\n",
        "X[\"rolling_std_14\"] = hist[\"Close\"].rolling(14).std()\n",
        "X[\"pct_change\"] = hist[\"Close\"].pct_change()\n",
        "X = X.dropna()\n",
        "\n",
        "# The output that we wish to predict is tmr's closing value from historical data\n",
        "# The output at day i will be the closing value at day (i + 1)\n",
        "y = X[\"Close\"].shift(-1)\n",
        "\n",
        "# Drop the last row as we don't have an output for the present day\n",
        "y = y.drop(y.index[-1])\n",
        "X = X.drop(X.index[-1])\n",
        "\n",
        "# Number of features\n",
        "NUM_FEATURES = X.shape[1]\n",
        "\n",
        "print(\"Size of y: \", y.shape)\n",
        "print(\"Size of X: \", X.shape)\n",
        "\n",
        "\n",
        "\n",
        "def build_windows(X, y, window_size):\n",
        "    Xw, yw = [], []\n",
        "\n",
        "    for i in range(window_size - 1 , len(X)):\n",
        "\n",
        "        # input: days (i - window_size + 1), (i - window_size + 2), ..., i\n",
        "        Xw.append(X.values[i - window_size + 1:i + 1, :])\n",
        "\n",
        "        # output: next-day close => close at day (i + 1) => y[i]\n",
        "        yw.append(y.values[i])\n",
        "\n",
        "    Xw = np.stack(Xw).reshape(-1, window_size * NUM_FEATURES) # (N, W*F)\n",
        "    yw = np.array(yw).reshape(-1, 1) # (N, 1)\n",
        "\n",
        "    return Xw, yw\n",
        "\n",
        "Xw, yw = build_windows(X, y, WINDOW)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Ref: https://medium.com/@mn05052002/building-a-simple-mlp-from-scratch-using-pytorch-7d50ca66512b\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "# Standardize the data for training performance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_ds = TensorDataset(X_train, y_train)\n",
        "test_ds = TensorDataset(X_test, y_test)\n",
        "val_ds = TensorDataset(X_val, y_val)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
        "test_dl = DataLoader(test_ds, batch_size=64, shuffle=False, drop_last=False)\n",
        "val_dl = DataLoader(val_ds, batch_size=64, shuffle=False, drop_last=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "nHG4Z3yup1hY",
        "outputId": "3cd33868-042b-4247-efbf-c7c9d39a70d0"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             Parameter                                       Value\n",
              "0    Input Window Size                                          30\n",
              "1     Input Data Range                                         max\n",
              "2        Hidden Layers                                   [128, 64]\n",
              "3  Activation Function  <class 'torch.nn.modules.activation.ReLU'>\n",
              "4            Optimizer             <class 'torch.optim.adam.Adam'>\n",
              "5            Dropout P                                         0.1\n",
              "6          Eval Metric     <class 'torch.nn.modules.loss.MSELoss'>\n",
              "7           Batch Size                                          64\n",
              "8        Learning Rate                                       0.001\n",
              "9             Patience                                           5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf3387a6-ecfc-4c08-b076-4b44a36ecdc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Parameter</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Input Window Size</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Input Data Range</td>\n",
              "      <td>max</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hidden Layers</td>\n",
              "      <td>[128, 64]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Activation Function</td>\n",
              "      <td>&lt;class 'torch.nn.modules.activation.ReLU'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Optimizer</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Dropout P</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Eval Metric</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.MSELoss'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Batch Size</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Learning Rate</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Patience</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf3387a6-ecfc-4c08-b076-4b44a36ecdc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf3387a6-ecfc-4c08-b076-4b44a36ecdc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf3387a6-ecfc-4c08-b076-4b44a36ecdc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4079d3b6-7994-4764-8af5-c0955e03ea08\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4079d3b6-7994-4764-8af5-c0955e03ea08')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4079d3b6-7994-4764-8af5-c0955e03ea08 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_724b75a7-8ca2-48b9-8b7c-33ef5467ee51\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('params')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_724b75a7-8ca2-48b9-8b7c-33ef5467ee51 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('params');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "params",
              "summary": "{\n  \"name\": \"params\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Parameter\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Learning Rate\",\n          \"Input Data Range\",\n          \"Dropout P\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                 Open        High         Low       Close  \\\n",
              "Date                                                                        \n",
              "2025-10-16 00:00:00-04:00  248.250000  249.039993  245.130005  247.449997   \n",
              "2025-10-17 00:00:00-04:00  248.020004  253.380005  247.270004  252.289993   \n",
              "2025-10-20 00:00:00-04:00  255.889999  264.380005  255.630005  262.239990   \n",
              "2025-10-21 00:00:00-04:00  261.880005  265.290009  261.829987  262.769989   \n",
              "2025-10-22 00:00:00-04:00  262.649994  262.850006  255.429993  258.450012   \n",
              "\n",
              "                             Volume  Dividends  Stock Splits  \n",
              "Date                                                          \n",
              "2025-10-16 00:00:00-04:00  39777000        0.0           0.0  \n",
              "2025-10-17 00:00:00-04:00  49147000        0.0           0.0  \n",
              "2025-10-20 00:00:00-04:00  90483000        0.0           0.0  \n",
              "2025-10-21 00:00:00-04:00  46695900        0.0           0.0  \n",
              "2025-10-22 00:00:00-04:00  44954300        0.0           0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86328a04-75ea-4852-804c-de523c338367\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-10-16 00:00:00-04:00</th>\n",
              "      <td>248.250000</td>\n",
              "      <td>249.039993</td>\n",
              "      <td>245.130005</td>\n",
              "      <td>247.449997</td>\n",
              "      <td>39777000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-17 00:00:00-04:00</th>\n",
              "      <td>248.020004</td>\n",
              "      <td>253.380005</td>\n",
              "      <td>247.270004</td>\n",
              "      <td>252.289993</td>\n",
              "      <td>49147000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-20 00:00:00-04:00</th>\n",
              "      <td>255.889999</td>\n",
              "      <td>264.380005</td>\n",
              "      <td>255.630005</td>\n",
              "      <td>262.239990</td>\n",
              "      <td>90483000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-21 00:00:00-04:00</th>\n",
              "      <td>261.880005</td>\n",
              "      <td>265.290009</td>\n",
              "      <td>261.829987</td>\n",
              "      <td>262.769989</td>\n",
              "      <td>46695900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-22 00:00:00-04:00</th>\n",
              "      <td>262.649994</td>\n",
              "      <td>262.850006</td>\n",
              "      <td>255.429993</td>\n",
              "      <td>258.450012</td>\n",
              "      <td>44954300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86328a04-75ea-4852-804c-de523c338367')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86328a04-75ea-4852-804c-de523c338367 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86328a04-75ea-4852-804c-de523c338367');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-873ab48e-b76c-4693-8dff-8d2ce269e449\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-873ab48e-b76c-4693-8dff-8d2ce269e449')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-873ab48e-b76c-4693-8dff-8d2ce269e449 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"val_dl = DataLoader(val_ds, batch_size=64, shuffle=False, drop_last=False)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-10-16 00:00:00-04:00\",\n        \"max\": \"2025-10-22 00:00:00-04:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2025-10-17 00:00:00-04:00\",\n          \"2025-10-22 00:00:00-04:00\",\n          \"2025-10-20 00:00:00-04:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.077439357271428,\n        \"min\": 248.02000427246094,\n        \"max\": 262.6499938964844,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          248.02000427246094,\n          262.6499938964844,\n          255.88999938964844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.3163612252542745,\n        \"min\": 249.0399932861328,\n        \"max\": 265.2900085449219,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          253.3800048828125,\n          262.8500061035156,\n          264.3800048828125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.810714131339862,\n        \"min\": 245.1300048828125,\n        \"max\": 261.8299865722656,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          247.27000427246094,\n          255.42999267578125,\n          255.6300048828125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.62554742312618,\n        \"min\": 247.4499969482422,\n        \"max\": 262.7699890136719,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          252.2899932861328,\n          258.45001220703125,\n          262.239990234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20565782,\n        \"min\": 39777000,\n        \"max\": 90483000,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          49147000,\n          44954300,\n          90483000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dividends\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stock Splits\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of y:  (11293,)\n",
            "Size of X:  (11293, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Run the same 1D-CNN for window sizes 5, 20, 100 (30 epochs each) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows for this size ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Splits (chronological)\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model (Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->Flatten->Dropout(0.1)->Linear->1)\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv1d(in_ch, 32, kernel_size=3, padding=1)\n",
        "            self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "            self.act   = nn.ReLU()\n",
        "            self.drop  = nn.Dropout(0.1)\n",
        "            self.fc    = nn.Linear(64 * seq_len, 1)\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.conv1(x))\n",
        "            x = self.act(self.conv2(x))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.drop(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train exactly 30 epochs\n",
        "    for epoch in range(1, 30 + 1):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n   += xb.size(0)\n",
        "\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse   = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run the three window sizes ---\n",
        "results = {}\n",
        "for W in [5, 20, 100]:\n",
        "    results[W] = run_window(W)\n",
        "\n",
        "print(\"\\nSummary (RMSE):\", {W: f\"{rmse:.4f}\" for W, (_, rmse) in results.items()})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uzbuErdp5gJ",
        "outputId": "cd7a8367-ade1-4558-b1ca-ea115d121be8"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5] Epoch 01 | Train MSE: 10.873691 | Val MSE: 12.871126\n",
            "[W=  5] Epoch 02 | Train MSE: 0.211416 | Val MSE: 5.353408\n",
            "[W=  5] Epoch 03 | Train MSE: 0.129434 | Val MSE: 6.214938\n",
            "[W=  5] Epoch 04 | Train MSE: 0.116763 | Val MSE: 5.933214\n",
            "[W=  5] Epoch 05 | Train MSE: 0.105047 | Val MSE: 6.244199\n",
            "[W=  5] Epoch 06 | Train MSE: 0.101646 | Val MSE: 10.004050\n",
            "[W=  5] Epoch 07 | Train MSE: 0.099526 | Val MSE: 4.682810\n",
            "[W=  5] Epoch 08 | Train MSE: 0.108315 | Val MSE: 4.867618\n",
            "[W=  5] Epoch 09 | Train MSE: 0.086500 | Val MSE: 4.565565\n",
            "[W=  5] Epoch 10 | Train MSE: 0.095928 | Val MSE: 4.439757\n",
            "[W=  5] Epoch 11 | Train MSE: 0.090919 | Val MSE: 8.006540\n",
            "[W=  5] Epoch 12 | Train MSE: 0.085079 | Val MSE: 4.409769\n",
            "[W=  5] Epoch 13 | Train MSE: 0.074526 | Val MSE: 4.349424\n",
            "[W=  5] Epoch 14 | Train MSE: 0.073123 | Val MSE: 5.242486\n",
            "[W=  5] Epoch 15 | Train MSE: 0.078477 | Val MSE: 6.831871\n",
            "[W=  5] Epoch 16 | Train MSE: 0.083380 | Val MSE: 6.932369\n",
            "[W=  5] Epoch 17 | Train MSE: 0.084322 | Val MSE: 5.554038\n",
            "[W=  5] Epoch 18 | Train MSE: 0.075363 | Val MSE: 3.999989\n",
            "[W=  5] Epoch 19 | Train MSE: 0.083335 | Val MSE: 4.607469\n",
            "[W=  5] Epoch 20 | Train MSE: 0.080251 | Val MSE: 5.574531\n",
            "[W=  5] Epoch 21 | Train MSE: 0.087364 | Val MSE: 5.280712\n",
            "[W=  5] Epoch 22 | Train MSE: 0.070483 | Val MSE: 7.832298\n",
            "[W=  5] Epoch 23 | Train MSE: 0.081104 | Val MSE: 4.141405\n",
            "[W=  5] Epoch 24 | Train MSE: 0.072859 | Val MSE: 4.360537\n",
            "[W=  5] Epoch 25 | Train MSE: 0.075856 | Val MSE: 4.837352\n",
            "[W=  5] Epoch 26 | Train MSE: 0.070167 | Val MSE: 4.188855\n",
            "[W=  5] Epoch 27 | Train MSE: 0.084851 | Val MSE: 5.065472\n",
            "[W=  5] Epoch 28 | Train MSE: 0.072332 | Val MSE: 11.899705\n",
            "[W=  5] Epoch 29 | Train MSE: 0.070009 | Val MSE: 4.026819\n",
            "[W=  5] Epoch 30 | Train MSE: 0.072225 | Val MSE: 4.346164\n",
            "[W=  5] Test MSE: 28.743272 | Test RMSE: 5.361275\n",
            "[W= 20] Epoch 01 | Train MSE: 6.479723 | Val MSE: 22.239905\n",
            "[W= 20] Epoch 02 | Train MSE: 0.153373 | Val MSE: 15.462656\n",
            "[W= 20] Epoch 03 | Train MSE: 0.098946 | Val MSE: 19.927045\n",
            "[W= 20] Epoch 04 | Train MSE: 0.076011 | Val MSE: 15.258236\n",
            "[W= 20] Epoch 05 | Train MSE: 0.065326 | Val MSE: 14.723686\n",
            "[W= 20] Epoch 06 | Train MSE: 0.061531 | Val MSE: 13.816138\n",
            "[W= 20] Epoch 07 | Train MSE: 0.055452 | Val MSE: 15.105536\n",
            "[W= 20] Epoch 08 | Train MSE: 0.055422 | Val MSE: 12.716992\n",
            "[W= 20] Epoch 09 | Train MSE: 0.058796 | Val MSE: 12.365455\n",
            "[W= 20] Epoch 10 | Train MSE: 0.050522 | Val MSE: 13.008127\n",
            "[W= 20] Epoch 11 | Train MSE: 0.073790 | Val MSE: 14.991373\n",
            "[W= 20] Epoch 12 | Train MSE: 0.072478 | Val MSE: 12.337111\n",
            "[W= 20] Epoch 13 | Train MSE: 0.048720 | Val MSE: 10.431164\n",
            "[W= 20] Epoch 14 | Train MSE: 0.058822 | Val MSE: 14.593169\n",
            "[W= 20] Epoch 15 | Train MSE: 0.062032 | Val MSE: 12.263768\n",
            "[W= 20] Epoch 16 | Train MSE: 0.049485 | Val MSE: 12.211982\n",
            "[W= 20] Epoch 17 | Train MSE: 0.054564 | Val MSE: 12.376733\n",
            "[W= 20] Epoch 18 | Train MSE: 0.057685 | Val MSE: 11.709915\n",
            "[W= 20] Epoch 19 | Train MSE: 0.055139 | Val MSE: 13.350898\n",
            "[W= 20] Epoch 20 | Train MSE: 0.069295 | Val MSE: 17.895567\n",
            "[W= 20] Epoch 21 | Train MSE: 0.066881 | Val MSE: 11.901606\n",
            "[W= 20] Epoch 22 | Train MSE: 0.043958 | Val MSE: 11.225997\n",
            "[W= 20] Epoch 23 | Train MSE: 0.046928 | Val MSE: 10.387819\n",
            "[W= 20] Epoch 24 | Train MSE: 0.043828 | Val MSE: 9.631918\n",
            "[W= 20] Epoch 25 | Train MSE: 0.057300 | Val MSE: 18.724560\n",
            "[W= 20] Epoch 26 | Train MSE: 0.052377 | Val MSE: 10.787198\n",
            "[W= 20] Epoch 27 | Train MSE: 0.045189 | Val MSE: 9.789242\n",
            "[W= 20] Epoch 28 | Train MSE: 0.048383 | Val MSE: 10.266193\n",
            "[W= 20] Epoch 29 | Train MSE: 0.051810 | Val MSE: 10.000611\n",
            "[W= 20] Epoch 30 | Train MSE: 0.054387 | Val MSE: 23.703665\n",
            "[W= 20] Test MSE: 132.869138 | Test RMSE: 11.526888\n",
            "[W=100] Epoch 01 | Train MSE: 2.764977 | Val MSE: 37.696058\n",
            "[W=100] Epoch 02 | Train MSE: 0.237949 | Val MSE: 57.873261\n",
            "[W=100] Epoch 03 | Train MSE: 0.109665 | Val MSE: 30.262675\n",
            "[W=100] Epoch 04 | Train MSE: 0.069853 | Val MSE: 43.572728\n",
            "[W=100] Epoch 05 | Train MSE: 0.057176 | Val MSE: 30.658398\n",
            "[W=100] Epoch 06 | Train MSE: 0.064534 | Val MSE: 25.476878\n",
            "[W=100] Epoch 07 | Train MSE: 0.041789 | Val MSE: 33.866451\n",
            "[W=100] Epoch 08 | Train MSE: 0.050734 | Val MSE: 25.956641\n",
            "[W=100] Epoch 09 | Train MSE: 0.043243 | Val MSE: 36.065900\n",
            "[W=100] Epoch 10 | Train MSE: 0.041845 | Val MSE: 31.789592\n",
            "[W=100] Epoch 11 | Train MSE: 0.053543 | Val MSE: 42.567983\n",
            "[W=100] Epoch 12 | Train MSE: 0.060324 | Val MSE: 41.142254\n",
            "[W=100] Epoch 13 | Train MSE: 0.037661 | Val MSE: 30.220507\n",
            "[W=100] Epoch 14 | Train MSE: 0.048422 | Val MSE: 40.482239\n",
            "[W=100] Epoch 15 | Train MSE: 0.056090 | Val MSE: 37.560915\n",
            "[W=100] Epoch 16 | Train MSE: 0.050203 | Val MSE: 27.080795\n",
            "[W=100] Epoch 17 | Train MSE: 0.040222 | Val MSE: 39.143921\n",
            "[W=100] Epoch 18 | Train MSE: 0.041920 | Val MSE: 29.887113\n",
            "[W=100] Epoch 19 | Train MSE: 0.039008 | Val MSE: 40.746996\n",
            "[W=100] Epoch 20 | Train MSE: 0.052222 | Val MSE: 35.938400\n",
            "[W=100] Epoch 21 | Train MSE: 0.041730 | Val MSE: 33.789163\n",
            "[W=100] Epoch 22 | Train MSE: 0.035350 | Val MSE: 23.843314\n",
            "[W=100] Epoch 23 | Train MSE: 0.035949 | Val MSE: 24.669685\n",
            "[W=100] Epoch 24 | Train MSE: 0.031627 | Val MSE: 38.606356\n",
            "[W=100] Epoch 25 | Train MSE: 0.049314 | Val MSE: 38.258832\n",
            "[W=100] Epoch 26 | Train MSE: 0.061537 | Val MSE: 22.597093\n",
            "[W=100] Epoch 27 | Train MSE: 0.067674 | Val MSE: 43.846594\n",
            "[W=100] Epoch 28 | Train MSE: 0.042523 | Val MSE: 50.898860\n",
            "[W=100] Epoch 29 | Train MSE: 0.038292 | Val MSE: 37.492870\n",
            "[W=100] Epoch 30 | Train MSE: 0.036981 | Val MSE: 39.363090\n",
            "[W=100] Test MSE: 104.990213 | Test RMSE: 10.246473\n",
            "\n",
            "Summary (RMSE): {5: '5.3613', 20: '11.5269', 100: '10.2465'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = 0.0001\n",
        "# ======== Run the same 1D-CNN but only for window size 5 (30 epochs) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows for this size (uses your existing build_windows) ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Splits (chronological)\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model (Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->Flatten->Dropout(0.1)->Linear->1)\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv1d(in_ch, 32, kernel_size=3, padding=1)\n",
        "            self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "            self.act   = nn.ReLU()\n",
        "            self.drop  = nn.Dropout(0.1)\n",
        "            self.fc    = nn.Linear(64 * seq_len, 1)\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.conv1(x))\n",
        "            x = self.act(self.conv2(x))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.drop(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train exactly 30 epochs\n",
        "    for epoch in range(1, 30 + 1):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n   += xb.size(0)\n",
        "\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse   = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run only window size = 5 ---\n",
        "results = {}\n",
        "results[5] = run_window(5)\n",
        "\n",
        "print(\"\\nSummary (RMSE):\", {5: f\"{results[5][1]:.4f}\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_bEgxl2At4q",
        "outputId": "001c024e-e4ab-4d02-bfef-14ba5275749e"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5] Epoch 01 | Train MSE: 3.011993 | Val MSE: 13.423723\n",
            "[W=  5] Epoch 02 | Train MSE: 0.218821 | Val MSE: 5.905666\n",
            "[W=  5] Epoch 03 | Train MSE: 0.149059 | Val MSE: 55.753285\n",
            "[W=  5] Epoch 04 | Train MSE: 0.270775 | Val MSE: 4.799765\n",
            "[W=  5] Epoch 05 | Train MSE: 0.211173 | Val MSE: 30.502096\n",
            "[W=  5] Epoch 06 | Train MSE: 0.127652 | Val MSE: 6.318776\n",
            "[W=  5] Epoch 07 | Train MSE: 0.148023 | Val MSE: 23.757667\n",
            "[W=  5] Epoch 08 | Train MSE: 0.170007 | Val MSE: 4.900283\n",
            "[W=  5] Epoch 09 | Train MSE: 0.264191 | Val MSE: 20.572170\n",
            "[W=  5] Epoch 10 | Train MSE: 0.368590 | Val MSE: 26.119159\n",
            "[W=  5] Epoch 11 | Train MSE: 0.216976 | Val MSE: 16.331482\n",
            "[W=  5] Epoch 12 | Train MSE: 0.144806 | Val MSE: 4.987337\n",
            "[W=  5] Epoch 13 | Train MSE: 0.165448 | Val MSE: 34.236317\n",
            "[W=  5] Epoch 14 | Train MSE: 0.251359 | Val MSE: 7.159016\n",
            "[W=  5] Epoch 15 | Train MSE: 0.148814 | Val MSE: 4.907583\n",
            "[W=  5] Epoch 16 | Train MSE: 0.234525 | Val MSE: 6.705678\n",
            "[W=  5] Epoch 17 | Train MSE: 0.231265 | Val MSE: 5.107980\n",
            "[W=  5] Epoch 18 | Train MSE: 0.142282 | Val MSE: 26.409588\n",
            "[W=  5] Epoch 19 | Train MSE: 0.147722 | Val MSE: 55.509403\n",
            "[W=  5] Epoch 20 | Train MSE: 0.180548 | Val MSE: 5.600773\n",
            "[W=  5] Epoch 21 | Train MSE: 0.142026 | Val MSE: 8.222957\n",
            "[W=  5] Epoch 22 | Train MSE: 0.135646 | Val MSE: 15.349862\n",
            "[W=  5] Epoch 23 | Train MSE: 0.195517 | Val MSE: 6.065633\n",
            "[W=  5] Epoch 24 | Train MSE: 0.124288 | Val MSE: 18.458144\n",
            "[W=  5] Epoch 25 | Train MSE: 0.124805 | Val MSE: 28.275948\n",
            "[W=  5] Epoch 26 | Train MSE: 0.198429 | Val MSE: 100.000036\n",
            "[W=  5] Epoch 27 | Train MSE: 0.224200 | Val MSE: 8.806809\n",
            "[W=  5] Epoch 28 | Train MSE: 0.119703 | Val MSE: 9.280209\n",
            "[W=  5] Epoch 29 | Train MSE: 0.146314 | Val MSE: 15.933403\n",
            "[W=  5] Epoch 30 | Train MSE: 0.138848 | Val MSE: 5.637314\n",
            "[W=  5] Test MSE: 40.543332 | Test RMSE: 6.367365\n",
            "\n",
            "Summary (RMSE): {5: '6.3674'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = 0.0001\n",
        "# ======== Run the same 1D-CNN but only for window size 5 (30 epochs) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows for this size (uses your existing build_windows) ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Splits (chronological)\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model (Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->Flatten->Dropout(0.1)->Linear->1)\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv1d(in_ch, 32, kernel_size=3, padding=1)\n",
        "            self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "            self.act   = nn.Tanh()\n",
        "            self.drop  = nn.Dropout(0.1)\n",
        "            self.fc    = nn.Linear(64 * seq_len, 1)\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.conv1(x))\n",
        "            x = self.act(self.conv2(x))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.drop(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train exactly 30 epochs\n",
        "    for epoch in range(1, 30 + 1):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n   += xb.size(0)\n",
        "\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse   = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run only window size = 5 ---\n",
        "results = {}\n",
        "results[5] = run_window(5)\n",
        "\n",
        "print(\"\\nSummary (RMSE):\", {5: f\"{results[5][1]:.4f}\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZeIG2QEC0HT",
        "outputId": "405d4b5b-c0ba-4eab-828e-cd18c80cffdd"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5] Epoch 01 | Train MSE: 3.954094 | Val MSE: 1691.410149\n",
            "[W=  5] Epoch 02 | Train MSE: 0.560902 | Val MSE: 1604.428353\n",
            "[W=  5] Epoch 03 | Train MSE: 0.423972 | Val MSE: 1658.676156\n",
            "[W=  5] Epoch 04 | Train MSE: 0.332844 | Val MSE: 1639.542252\n",
            "[W=  5] Epoch 05 | Train MSE: 0.284979 | Val MSE: 1567.443986\n",
            "[W=  5] Epoch 06 | Train MSE: 0.273738 | Val MSE: 1619.024176\n",
            "[W=  5] Epoch 07 | Train MSE: 0.251396 | Val MSE: 1509.468060\n",
            "[W=  5] Epoch 08 | Train MSE: 0.276822 | Val MSE: 1557.777144\n",
            "[W=  5] Epoch 09 | Train MSE: 0.302567 | Val MSE: 1514.999755\n",
            "[W=  5] Epoch 10 | Train MSE: 0.268685 | Val MSE: 1549.580078\n",
            "[W=  5] Epoch 11 | Train MSE: 0.244287 | Val MSE: 1552.336312\n",
            "[W=  5] Epoch 12 | Train MSE: 0.252256 | Val MSE: 1604.886123\n",
            "[W=  5] Epoch 13 | Train MSE: 0.179439 | Val MSE: 1548.025547\n",
            "[W=  5] Epoch 14 | Train MSE: 0.237772 | Val MSE: 1603.377997\n",
            "[W=  5] Epoch 15 | Train MSE: 0.171546 | Val MSE: 1476.560664\n",
            "[W=  5] Epoch 16 | Train MSE: 0.248303 | Val MSE: 1602.360143\n",
            "[W=  5] Epoch 17 | Train MSE: 0.186283 | Val MSE: 1468.347895\n",
            "[W=  5] Epoch 18 | Train MSE: 0.211601 | Val MSE: 1574.274375\n",
            "[W=  5] Epoch 19 | Train MSE: 0.264224 | Val MSE: 1521.642437\n",
            "[W=  5] Epoch 20 | Train MSE: 0.226930 | Val MSE: 1475.574170\n",
            "[W=  5] Epoch 21 | Train MSE: 0.212257 | Val MSE: 1523.747111\n",
            "[W=  5] Epoch 22 | Train MSE: 0.195573 | Val MSE: 1617.062399\n",
            "[W=  5] Epoch 23 | Train MSE: 0.208036 | Val MSE: 1572.537035\n",
            "[W=  5] Epoch 24 | Train MSE: 0.189720 | Val MSE: 1482.836109\n",
            "[W=  5] Epoch 25 | Train MSE: 0.175218 | Val MSE: 1561.383320\n",
            "[W=  5] Epoch 26 | Train MSE: 0.271188 | Val MSE: 1824.302540\n",
            "[W=  5] Epoch 27 | Train MSE: 0.229609 | Val MSE: 1573.848494\n",
            "[W=  5] Epoch 28 | Train MSE: 0.264031 | Val MSE: 1563.388953\n",
            "[W=  5] Epoch 29 | Train MSE: 0.199877 | Val MSE: 1600.334946\n",
            "[W=  5] Epoch 30 | Train MSE: 0.173590 | Val MSE: 1593.842931\n",
            "[W=  5] Test MSE: 22372.768597 | Test RMSE: 149.575294\n",
            "\n",
            "Summary (RMSE): {5: '149.5753'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kernel 5\n",
        "# ======== Run the same 1D-CNN but only for window size 5 (30 epochs) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows for this size (uses your existing build_windows) ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Splits (chronological)\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model (Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->Flatten->Dropout(0.1)->Linear->1)\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv1d(in_ch, 32, kernel_size=5, padding=2)\n",
        "            self.conv2 = nn.Conv1d(32, 64, kernel_size=5, padding=2)\n",
        "            self.act   = nn.ReLU()\n",
        "            self.drop  = nn.Dropout(0.1)\n",
        "            self.fc    = nn.Linear(64 * seq_len, 1)\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.conv1(x))\n",
        "            x = self.act(self.conv2(x))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.drop(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train exactly 30 epochs\n",
        "    for epoch in range(1, 30 + 1):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n   += xb.size(0)\n",
        "\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse   = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run only window size = 5 ---\n",
        "results = {}\n",
        "results[5] = run_window(5)\n",
        "\n",
        "print(\"\\nSummary (RMSE):\", {5: f\"{results[5][1]:.4f}\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydRfGG5NEj3f",
        "outputId": "cd9a69be-d83a-4380-8c10-82f15de38575"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5] Epoch 01 | Train MSE: 10.653061 | Val MSE: 17.825944\n",
            "[W=  5] Epoch 02 | Train MSE: 0.358550 | Val MSE: 12.689399\n",
            "[W=  5] Epoch 03 | Train MSE: 0.142124 | Val MSE: 10.904785\n",
            "[W=  5] Epoch 04 | Train MSE: 0.136518 | Val MSE: 5.996675\n",
            "[W=  5] Epoch 05 | Train MSE: 0.106497 | Val MSE: 10.736584\n",
            "[W=  5] Epoch 06 | Train MSE: 0.096925 | Val MSE: 12.127007\n",
            "[W=  5] Epoch 07 | Train MSE: 0.101874 | Val MSE: 4.899020\n",
            "[W=  5] Epoch 08 | Train MSE: 0.105574 | Val MSE: 10.192790\n",
            "[W=  5] Epoch 09 | Train MSE: 0.105982 | Val MSE: 14.784644\n",
            "[W=  5] Epoch 10 | Train MSE: 0.102503 | Val MSE: 4.563679\n",
            "[W=  5] Epoch 11 | Train MSE: 0.097597 | Val MSE: 6.452015\n",
            "[W=  5] Epoch 12 | Train MSE: 0.110021 | Val MSE: 12.343162\n",
            "[W=  5] Epoch 13 | Train MSE: 0.094375 | Val MSE: 5.556150\n",
            "[W=  5] Epoch 14 | Train MSE: 0.092692 | Val MSE: 12.480950\n",
            "[W=  5] Epoch 15 | Train MSE: 0.079572 | Val MSE: 4.539896\n",
            "[W=  5] Epoch 16 | Train MSE: 0.090994 | Val MSE: 5.261024\n",
            "[W=  5] Epoch 17 | Train MSE: 0.086586 | Val MSE: 4.575740\n",
            "[W=  5] Epoch 18 | Train MSE: 0.082543 | Val MSE: 4.430722\n",
            "[W=  5] Epoch 19 | Train MSE: 0.090839 | Val MSE: 4.085380\n",
            "[W=  5] Epoch 20 | Train MSE: 0.093451 | Val MSE: 6.491517\n",
            "[W=  5] Epoch 21 | Train MSE: 0.075149 | Val MSE: 5.234882\n",
            "[W=  5] Epoch 22 | Train MSE: 0.106114 | Val MSE: 4.870912\n",
            "[W=  5] Epoch 23 | Train MSE: 0.096013 | Val MSE: 9.928075\n",
            "[W=  5] Epoch 24 | Train MSE: 0.088135 | Val MSE: 19.431563\n",
            "[W=  5] Epoch 25 | Train MSE: 0.145283 | Val MSE: 14.708473\n",
            "[W=  5] Epoch 26 | Train MSE: 0.092558 | Val MSE: 4.864570\n",
            "[W=  5] Epoch 27 | Train MSE: 0.084375 | Val MSE: 11.246711\n",
            "[W=  5] Epoch 28 | Train MSE: 0.083040 | Val MSE: 5.706617\n",
            "[W=  5] Epoch 29 | Train MSE: 0.076613 | Val MSE: 5.577829\n",
            "[W=  5] Epoch 30 | Train MSE: 0.080595 | Val MSE: 4.997098\n",
            "[W=  5] Test MSE: 29.745072 | Test RMSE: 5.453904\n",
            "\n",
            "Summary (RMSE): {5: '5.4539'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PERIOD = \"max\"\n",
        "# ======== Run the same 1D-CNN but only for window size 5 (30 epochs) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows for this size (uses your existing build_windows) ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Splits (chronological)\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model (Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->Flatten->Dropout(0.1)->Linear->1)\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv1d(in_ch, 32, kernel_size=3, padding=1)\n",
        "            self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "            self.act   = nn.ReLU()\n",
        "            self.pool  = nn.AdaptiveAvgPool1d(1)   # ← Added pooling layer\n",
        "            self.drop  = nn.Dropout(0.1)\n",
        "            self.fc    = nn.Linear(64, 1)          # ← Changed input size (64, not 64*seq_len)\n",
        "\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.conv1(x))\n",
        "            x = self.act(self.conv2(x))\n",
        "            x = self.pool(x).squeeze(-1)           # ← Apply average pooling\n",
        "            x = self.drop(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train exactly 30 epochs\n",
        "    for epoch in range(1, 30 + 1):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n   += xb.size(0)\n",
        "\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse   = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run only window size = 5 ---\n",
        "results = {}\n",
        "results[5] = run_window(5)\n",
        "\n",
        "print(\"\\nSummary (RMSE):\", {5: f\"{results[5][1]:.4f}\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLa9080OHUK2",
        "outputId": "ea1d723d-5c12-4123-a712-5dc33683e694"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5] Epoch 01 | Train MSE: 15.522978 | Val MSE: 115.109838\n",
            "[W=  5] Epoch 02 | Train MSE: 0.522287 | Val MSE: 11.268571\n",
            "[W=  5] Epoch 03 | Train MSE: 0.314716 | Val MSE: 27.023598\n",
            "[W=  5] Epoch 04 | Train MSE: 0.295885 | Val MSE: 9.399158\n",
            "[W=  5] Epoch 05 | Train MSE: 0.299751 | Val MSE: 10.033674\n",
            "[W=  5] Epoch 06 | Train MSE: 0.280397 | Val MSE: 22.699244\n",
            "[W=  5] Epoch 07 | Train MSE: 0.282598 | Val MSE: 7.680905\n",
            "[W=  5] Epoch 08 | Train MSE: 0.311038 | Val MSE: 14.862578\n",
            "[W=  5] Epoch 09 | Train MSE: 0.294864 | Val MSE: 6.197982\n",
            "[W=  5] Epoch 10 | Train MSE: 0.252300 | Val MSE: 6.634321\n",
            "[W=  5] Epoch 11 | Train MSE: 0.301068 | Val MSE: 6.549924\n",
            "[W=  5] Epoch 12 | Train MSE: 0.276179 | Val MSE: 9.475229\n",
            "[W=  5] Epoch 13 | Train MSE: 0.267999 | Val MSE: 14.278427\n",
            "[W=  5] Epoch 14 | Train MSE: 0.282504 | Val MSE: 12.520250\n",
            "[W=  5] Epoch 15 | Train MSE: 0.249001 | Val MSE: 5.054484\n",
            "[W=  5] Epoch 16 | Train MSE: 0.265138 | Val MSE: 5.312508\n",
            "[W=  5] Epoch 17 | Train MSE: 0.261710 | Val MSE: 7.014823\n",
            "[W=  5] Epoch 18 | Train MSE: 0.272892 | Val MSE: 10.850325\n",
            "[W=  5] Epoch 19 | Train MSE: 0.258340 | Val MSE: 5.733433\n",
            "[W=  5] Epoch 20 | Train MSE: 0.255232 | Val MSE: 5.311479\n",
            "[W=  5] Epoch 21 | Train MSE: 0.264475 | Val MSE: 5.183363\n",
            "[W=  5] Epoch 22 | Train MSE: 0.258786 | Val MSE: 5.278825\n",
            "[W=  5] Epoch 23 | Train MSE: 0.249782 | Val MSE: 6.079584\n",
            "[W=  5] Epoch 24 | Train MSE: 0.271241 | Val MSE: 5.479007\n",
            "[W=  5] Epoch 25 | Train MSE: 0.253788 | Val MSE: 6.310342\n",
            "[W=  5] Epoch 26 | Train MSE: 0.242560 | Val MSE: 8.302746\n",
            "[W=  5] Epoch 27 | Train MSE: 0.251600 | Val MSE: 5.181124\n",
            "[W=  5] Epoch 28 | Train MSE: 0.244530 | Val MSE: 5.752763\n",
            "[W=  5] Epoch 29 | Train MSE: 0.275350 | Val MSE: 10.137519\n",
            "[W=  5] Epoch 30 | Train MSE: 0.291536 | Val MSE: 10.592601\n",
            "[W=  5] Test MSE: 67.596588 | Test RMSE: 8.221714\n",
            "\n",
            "Summary (RMSE): {5: '8.2217'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PERIOD = \"max\"\n",
        "# ======== Run the same 1D-CNN but only for window size 5 (30 epochs) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows for this size (uses your existing build_windows) ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Splits (chronological)\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model (Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->Flatten->Dropout(0.1)->Linear->1)\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv1d(in_ch, 32, kernel_size=3, padding=1)\n",
        "            self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "            self.act   = nn.ReLU()\n",
        "            self.drop  = nn.Dropout(0.1)\n",
        "            self.fc    = nn.Linear(64 * seq_len, 1)\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.conv1(x))\n",
        "            x = self.act(self.conv2(x))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.drop(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train exactly 30 epochs\n",
        "    for epoch in range(1, 30 + 1):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n   += xb.size(0)\n",
        "\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse   = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run only window size = 5 ---\n",
        "results = {}\n",
        "results[5] = run_window(5)\n",
        "\n",
        "print(\"\\nSummary (RMSE):\", {5: f\"{results[5][1]:.4f}\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlTTjU6vKLR0",
        "outputId": "b91b9c67-a38d-4a78-f3d8-2437601b5a7a"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5] Epoch 01 | Train MSE: 10.962754 | Val MSE: 89.065834\n",
            "[W=  5] Epoch 02 | Train MSE: 0.366383 | Val MSE: 6.880054\n",
            "[W=  5] Epoch 03 | Train MSE: 0.171685 | Val MSE: 9.043439\n",
            "[W=  5] Epoch 04 | Train MSE: 0.150316 | Val MSE: 6.984975\n",
            "[W=  5] Epoch 05 | Train MSE: 0.129612 | Val MSE: 7.349450\n",
            "[W=  5] Epoch 06 | Train MSE: 0.117366 | Val MSE: 6.361308\n",
            "[W=  5] Epoch 07 | Train MSE: 0.110884 | Val MSE: 10.353462\n",
            "[W=  5] Epoch 08 | Train MSE: 0.113521 | Val MSE: 7.521971\n",
            "[W=  5] Epoch 09 | Train MSE: 0.109628 | Val MSE: 6.055646\n",
            "[W=  5] Epoch 10 | Train MSE: 0.103785 | Val MSE: 5.747351\n",
            "[W=  5] Epoch 11 | Train MSE: 0.095646 | Val MSE: 6.681102\n",
            "[W=  5] Epoch 12 | Train MSE: 0.086547 | Val MSE: 9.113407\n",
            "[W=  5] Epoch 13 | Train MSE: 0.093448 | Val MSE: 5.648479\n",
            "[W=  5] Epoch 14 | Train MSE: 0.098443 | Val MSE: 5.488804\n",
            "[W=  5] Epoch 15 | Train MSE: 0.092594 | Val MSE: 10.749243\n",
            "[W=  5] Epoch 16 | Train MSE: 0.082443 | Val MSE: 9.405755\n",
            "[W=  5] Epoch 17 | Train MSE: 0.107809 | Val MSE: 8.623280\n",
            "[W=  5] Epoch 18 | Train MSE: 0.121332 | Val MSE: 5.656752\n",
            "[W=  5] Epoch 19 | Train MSE: 0.084996 | Val MSE: 5.359679\n",
            "[W=  5] Epoch 20 | Train MSE: 0.079949 | Val MSE: 4.484593\n",
            "[W=  5] Epoch 21 | Train MSE: 0.090928 | Val MSE: 10.548399\n",
            "[W=  5] Epoch 22 | Train MSE: 0.078243 | Val MSE: 13.745622\n",
            "[W=  5] Epoch 23 | Train MSE: 0.078892 | Val MSE: 6.578274\n",
            "[W=  5] Epoch 24 | Train MSE: 0.081443 | Val MSE: 4.787583\n",
            "[W=  5] Epoch 25 | Train MSE: 0.094535 | Val MSE: 7.116056\n",
            "[W=  5] Epoch 26 | Train MSE: 0.089820 | Val MSE: 7.976989\n",
            "[W=  5] Epoch 27 | Train MSE: 0.075520 | Val MSE: 9.249086\n",
            "[W=  5] Epoch 28 | Train MSE: 0.068878 | Val MSE: 5.020301\n",
            "[W=  5] Epoch 29 | Train MSE: 0.071694 | Val MSE: 4.674801\n",
            "[W=  5] Epoch 30 | Train MSE: 0.088807 | Val MSE: 12.707175\n",
            "[W=  5] Test MSE: 79.858979 | Test RMSE: 8.936385\n",
            "\n",
            "Summary (RMSE): {5: '8.9364'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Conv64\n",
        "PERIOD = \"max\"\n",
        "# ======== Run the same 1D-CNN but only for window size 5 (30 epochs) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows for this size (uses your existing build_windows) ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Splits (chronological)\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model (Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->Flatten->Dropout(0.1)->Linear->1)\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv1d(in_ch, 64, kernel_size=3, padding=1)   # ← changed 32 → 64\n",
        "            self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)     # ← updated input/output channels\n",
        "            self.act   = nn.ReLU()\n",
        "            self.drop  = nn.Dropout(0.1)\n",
        "            self.fc    = nn.Linear(128 * seq_len, 1)                      # ← updated input size (128 × seq_len)\n",
        "\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.conv1(x))\n",
        "            x = self.act(self.conv2(x))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.drop(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train exactly 30 epochs\n",
        "    for epoch in range(1, 30 + 1):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n   += xb.size(0)\n",
        "\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse   = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run only window size = 5 ---\n",
        "results = {}\n",
        "results[5] = run_window(5)\n",
        "\n",
        "print(\"\\nSummary (RMSE):\", {5: f\"{results[5][1]:.4f}\"})"
      ],
      "metadata": {
        "id": "BJnNfK8jR8gu",
        "outputId": "e3fe4074-31c4-4a31-c156-60672f428fdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5] Epoch 01 | Train MSE: 48706.301161 | Val MSE: 54033.847656\n",
            "[W=  5] Epoch 02 | Train MSE: 48477.344088 | Val MSE: 53807.539062\n",
            "[W=  5] Epoch 03 | Train MSE: 48171.894193 | Val MSE: 53491.417969\n",
            "[W=  5] Epoch 04 | Train MSE: 47739.905785 | Val MSE: 53049.675781\n",
            "[W=  5] Epoch 05 | Train MSE: 47142.214084 | Val MSE: 52446.925781\n",
            "[W=  5] Epoch 06 | Train MSE: 46323.206989 | Val MSE: 51643.832031\n",
            "[W=  5] Epoch 07 | Train MSE: 45236.809713 | Val MSE: 50599.582031\n",
            "[W=  5] Epoch 08 | Train MSE: 43816.969975 | Val MSE: 49266.675781\n",
            "[W=  5] Epoch 09 | Train MSE: 42004.051056 | Val MSE: 47597.191406\n",
            "[W=  5] Epoch 10 | Train MSE: 39788.418940 | Val MSE: 45541.652344\n",
            "[W=  5] Epoch 11 | Train MSE: 37117.104012 | Val MSE: 43055.058594\n",
            "[W=  5] Epoch 12 | Train MSE: 33900.350591 | Val MSE: 40106.964844\n",
            "[W=  5] Epoch 13 | Train MSE: 30209.531503 | Val MSE: 36701.191406\n",
            "[W=  5] Epoch 14 | Train MSE: 26155.581482 | Val MSE: 32848.023438\n",
            "[W=  5] Epoch 15 | Train MSE: 21667.893877 | Val MSE: 28623.986328\n",
            "[W=  5] Epoch 16 | Train MSE: 17390.704054 | Val MSE: 24099.255859\n",
            "[W=  5] Epoch 17 | Train MSE: 13199.898691 | Val MSE: 19486.755859\n",
            "[W=  5] Epoch 18 | Train MSE: 9479.997398 | Val MSE: 15024.680664\n",
            "[W=  5] Epoch 19 | Train MSE: 6907.676190 | Val MSE: 11058.460938\n",
            "[W=  5] Epoch 20 | Train MSE: 5329.195743 | Val MSE: 7921.940430\n",
            "[W=  5] Epoch 21 | Train MSE: 4792.089567 | Val MSE: 5759.803223\n",
            "[W=  5] Epoch 22 | Train MSE: 5006.540431 | Val MSE: 4559.916992\n",
            "[W=  5] Epoch 23 | Train MSE: 5263.674960 | Val MSE: 4067.868652\n",
            "[W=  5] Epoch 24 | Train MSE: 5062.095743 | Val MSE: 4098.104004\n",
            "[W=  5] Epoch 25 | Train MSE: 4613.206226 | Val MSE: 4482.787109\n",
            "[W=  5] Epoch 26 | Train MSE: 4170.155339 | Val MSE: 5002.777344\n",
            "[W=  5] Epoch 27 | Train MSE: 3884.431325 | Val MSE: 5515.952637\n",
            "[W=  5] Epoch 28 | Train MSE: 3630.370931 | Val MSE: 5874.913086\n",
            "[W=  5] Epoch 29 | Train MSE: 3589.122815 | Val MSE: 6083.400879\n",
            "[W=  5] Epoch 30 | Train MSE: 3555.207819 | Val MSE: 6066.129883\n",
            "[W=  5] Test MSE: 6597.611816 | Test RMSE: 81.225684\n",
            "\n",
            "Summary (RMSE): {5: '81.2257'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#depth 3\n",
        "PERIOD = \"max\"\n",
        "# ======== Run the same 1D-CNN but only for window size 5 (30 epochs) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows for this size (uses your existing build_windows) ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Splits (chronological)\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model (Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->Conv1d(64->128)->ReLU->Flatten->Dropout(0.1)->Linear->1)\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv1d(in_ch, 32, kernel_size=3, padding=1)\n",
        "            self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "            self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)   # ← added third conv layer\n",
        "            self.act   = nn.ReLU()\n",
        "            self.drop  = nn.Dropout(0.1)\n",
        "            self.fc    = nn.Linear(128 * seq_len, 1)                   # ← updated input size\n",
        "\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.conv1(x))\n",
        "            x = self.act(self.conv2(x))\n",
        "            x = self.act(self.conv3(x))                                # ← added forward pass for conv3\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.drop(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "    # Training setup\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Evaluation function\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train 30 epochs\n",
        "    for epoch in range(1, 31):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n += xb.size(0)\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run only window size = 5 ---\n",
        "results = {}\n",
        "results[5] = run_window(5)\n",
        "print(\"\\nSummary (RMSE):\", {5: f\"{results[5][1]:.4f}\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5Byy74QLSg9",
        "outputId": "e56f16e3-e690-46cd-de90-351e8968be40"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5] Epoch 01 | Train MSE: 6.148822 | Val MSE: 6.864428\n",
            "[W=  5] Epoch 02 | Train MSE: 0.123506 | Val MSE: 10.159603\n",
            "[W=  5] Epoch 03 | Train MSE: 0.103401 | Val MSE: 8.721442\n",
            "[W=  5] Epoch 04 | Train MSE: 0.087203 | Val MSE: 6.857355\n",
            "[W=  5] Epoch 05 | Train MSE: 0.079216 | Val MSE: 8.915024\n",
            "[W=  5] Epoch 06 | Train MSE: 0.082226 | Val MSE: 12.288895\n",
            "[W=  5] Epoch 07 | Train MSE: 0.081886 | Val MSE: 5.687261\n",
            "[W=  5] Epoch 08 | Train MSE: 0.085390 | Val MSE: 7.303789\n",
            "[W=  5] Epoch 09 | Train MSE: 0.073529 | Val MSE: 5.571581\n",
            "[W=  5] Epoch 10 | Train MSE: 0.085984 | Val MSE: 4.659429\n",
            "[W=  5] Epoch 11 | Train MSE: 0.074834 | Val MSE: 4.789211\n",
            "[W=  5] Epoch 12 | Train MSE: 0.079135 | Val MSE: 6.188665\n",
            "[W=  5] Epoch 13 | Train MSE: 0.073605 | Val MSE: 5.038219\n",
            "[W=  5] Epoch 14 | Train MSE: 0.076690 | Val MSE: 7.050550\n",
            "[W=  5] Epoch 15 | Train MSE: 0.061881 | Val MSE: 21.856019\n",
            "[W=  5] Epoch 16 | Train MSE: 0.086404 | Val MSE: 7.637629\n",
            "[W=  5] Epoch 17 | Train MSE: 0.076236 | Val MSE: 19.399492\n",
            "[W=  5] Epoch 18 | Train MSE: 0.070773 | Val MSE: 10.882260\n",
            "[W=  5] Epoch 19 | Train MSE: 0.066955 | Val MSE: 9.878488\n",
            "[W=  5] Epoch 20 | Train MSE: 0.078089 | Val MSE: 4.380571\n",
            "[W=  5] Epoch 21 | Train MSE: 0.079480 | Val MSE: 4.583800\n",
            "[W=  5] Epoch 22 | Train MSE: 0.068124 | Val MSE: 5.508797\n",
            "[W=  5] Epoch 23 | Train MSE: 0.080979 | Val MSE: 13.158460\n",
            "[W=  5] Epoch 24 | Train MSE: 0.076223 | Val MSE: 6.906089\n",
            "[W=  5] Epoch 25 | Train MSE: 0.065225 | Val MSE: 4.357300\n",
            "[W=  5] Epoch 26 | Train MSE: 0.064278 | Val MSE: 4.348833\n",
            "[W=  5] Epoch 27 | Train MSE: 0.054229 | Val MSE: 5.698082\n",
            "[W=  5] Epoch 28 | Train MSE: 0.064196 | Val MSE: 5.501900\n",
            "[W=  5] Epoch 29 | Train MSE: 0.086322 | Val MSE: 4.483242\n",
            "[W=  5] Epoch 30 | Train MSE: 0.050535 | Val MSE: 7.927871\n",
            "[W=  5] Test MSE: 47.253677 | Test RMSE: 6.874131\n",
            "\n",
            "Summary (RMSE): {5: '6.8741'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularization (Dropout + L2 weight decay)\n",
        "PERIOD = \"max\"\n",
        "\n",
        "# ======== 1D-CNN (Regularization) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows (using your existing build_windows) ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Chronological 80/10/10 split\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Convert to tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val, dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Data loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False)\n",
        "\n",
        "    # -------- Regularized CNN --------\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            # Smaller model + dropout layers for regularisation\n",
        "            self.conv1 = nn.Conv1d(in_ch, 64, kernel_size=3, padding=1)\n",
        "            self.bn1   = nn.BatchNorm1d(64)           # optional batchnorm\n",
        "            self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
        "            self.bn2   = nn.BatchNorm1d(32)\n",
        "            self.act   = nn.ReLU()\n",
        "            self.drop1 = nn.Dropout(0.3)              # stronger dropout\n",
        "            self.drop2 = nn.Dropout(0.3)\n",
        "            self.fc    = nn.Linear(32 * seq_len, 1)\n",
        "\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.bn1(self.conv1(x)))\n",
        "            x = self.drop1(x)\n",
        "            x = self.act(self.bn2(self.conv2(x)))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.drop2(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Add L2 regularisation via weight_decay\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "    # Evaluation helper\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train (30 epochs)\n",
        "    for epoch in range(1, 31):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n += xb.size(0)\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse   = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run only window size = 5 ---\n",
        "results = {}\n",
        "results[5] = run_window(5)\n",
        "print(\"\\nSummary (RMSE):\", {5: f\"{results[5][1]:.4f}\"})\n"
      ],
      "metadata": {
        "id": "9JaGMHSFRMZT",
        "outputId": "b4434f23-a5ff-4e97-808c-0c18743e80c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5] Epoch 01 | Train MSE: 10.811222 | Val MSE: 22.646416\n",
            "[W=  5] Epoch 02 | Train MSE: 2.497612 | Val MSE: 125.793776\n",
            "[W=  5] Epoch 03 | Train MSE: 2.052442 | Val MSE: 23.376213\n",
            "[W=  5] Epoch 04 | Train MSE: 1.572060 | Val MSE: 53.273380\n",
            "[W=  5] Epoch 05 | Train MSE: 1.564797 | Val MSE: 11.527203\n",
            "[W=  5] Epoch 06 | Train MSE: 1.544203 | Val MSE: 54.321782\n",
            "[W=  5] Epoch 07 | Train MSE: 1.418844 | Val MSE: 91.455404\n",
            "[W=  5] Epoch 08 | Train MSE: 1.127198 | Val MSE: 9.377269\n",
            "[W=  5] Epoch 09 | Train MSE: 1.105211 | Val MSE: 75.958079\n",
            "[W=  5] Epoch 10 | Train MSE: 1.033230 | Val MSE: 64.545634\n",
            "[W=  5] Epoch 11 | Train MSE: 1.146466 | Val MSE: 41.657715\n",
            "[W=  5] Epoch 12 | Train MSE: 1.047249 | Val MSE: 75.473957\n",
            "[W=  5] Epoch 13 | Train MSE: 0.953035 | Val MSE: 18.807046\n",
            "[W=  5] Epoch 14 | Train MSE: 0.871252 | Val MSE: 96.602239\n",
            "[W=  5] Epoch 15 | Train MSE: 0.850641 | Val MSE: 7.653217\n",
            "[W=  5] Epoch 16 | Train MSE: 0.879882 | Val MSE: 78.053208\n",
            "[W=  5] Epoch 17 | Train MSE: 0.825978 | Val MSE: 98.263148\n",
            "[W=  5] Epoch 18 | Train MSE: 0.800621 | Val MSE: 96.681147\n",
            "[W=  5] Epoch 19 | Train MSE: 0.914266 | Val MSE: 100.408427\n",
            "[W=  5] Epoch 20 | Train MSE: 0.801873 | Val MSE: 17.696883\n",
            "[W=  5] Epoch 21 | Train MSE: 0.712932 | Val MSE: 36.567938\n",
            "[W=  5] Epoch 22 | Train MSE: 0.711964 | Val MSE: 69.525461\n",
            "[W=  5] Epoch 23 | Train MSE: 0.728313 | Val MSE: 85.934716\n",
            "[W=  5] Epoch 24 | Train MSE: 0.711900 | Val MSE: 26.290460\n",
            "[W=  5] Epoch 25 | Train MSE: 0.799542 | Val MSE: 62.918253\n",
            "[W=  5] Epoch 26 | Train MSE: 0.682739 | Val MSE: 31.358099\n",
            "[W=  5] Epoch 27 | Train MSE: 0.671736 | Val MSE: 58.937019\n",
            "[W=  5] Epoch 28 | Train MSE: 0.810573 | Val MSE: 83.253124\n",
            "[W=  5] Epoch 29 | Train MSE: 0.703185 | Val MSE: 14.175935\n",
            "[W=  5] Epoch 30 | Train MSE: 0.720414 | Val MSE: 53.521287\n",
            "[W=  5] Test MSE: 619.948239 | Test RMSE: 24.898760\n",
            "\n",
            "Summary (RMSE): {5: '24.8988'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== 1D-CNN (window=5) using 1 year of data (30 epochs) ========\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import yfinance as yf\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------------- Data (1 year) ----------------\n",
        "TICKER = \"AAPL\"\n",
        "PERIOD = \"1y\"  # <-- one year\n",
        "tick = yf.Ticker(TICKER)\n",
        "hist = tick.history(period=PERIOD)\n",
        "display(hist.tail())\n",
        "\n",
        "# Feature table X (7 features) and next-day target y\n",
        "X = pd.DataFrame(index=hist.index)\n",
        "X[\"Close\"]           = hist[\"Close\"]\n",
        "X[\"Volume\"]          = hist[\"Volume\"]\n",
        "X[\"rolling_mean_3\"]  = hist[\"Close\"].rolling(3).mean()\n",
        "X[\"rolling_mean_14\"] = hist[\"Close\"].rolling(14).mean()\n",
        "X[\"rolling_std_3\"]   = hist[\"Close\"].rolling(3).std()\n",
        "X[\"rolling_std_14\"]  = hist[\"Close\"].rolling(14).std()\n",
        "X[\"pct_change\"]      = hist[\"Close\"].pct_change()\n",
        "X = X.dropna()\n",
        "\n",
        "y = X[\"Close\"].shift(-1)      # next-day Close\n",
        "y = y.drop(y.index[-1])\n",
        "X = X.drop(X.index[-1])\n",
        "\n",
        "NUM_FEATURES = X.shape[1]\n",
        "print(\"Size of X:\", X.shape, \"| Size of y:\", y.shape)\n",
        "\n",
        "# ---------------- Sliding windows (stride = 1 day) ----------------\n",
        "def build_windows(X_df: pd.DataFrame, y_sr: pd.Series, window_size: int):\n",
        "    Xv, yv = X_df.values, y_sr.values\n",
        "    W = window_size\n",
        "    xs, ys = [], []\n",
        "    # pair each window X[i-W+1:i+1] with y[i]  (y is already next-day close)\n",
        "    for i in range(W - 1, len(Xv)):\n",
        "        xs.append(Xv[i - W + 1 : i + 1, :])   # (W, F)\n",
        "        ys.append(yv[i])                       # scalar\n",
        "    Xw = np.stack(xs).reshape(-1, W * NUM_FEATURES).astype(np.float32)\n",
        "    yw = np.array(ys, dtype=np.float32).reshape(-1, 1)\n",
        "    return Xw, yw\n",
        "\n",
        "# ---------------- Runner (window=5) ----------------\n",
        "def run_window(window_size: int):\n",
        "    # Rebuild windows for this size\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Chronological 80/10/10 split\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val,   X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model: Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->\n",
        "\n",
        "\n",
        "\n",
        "    ERIOD = \"1m\"\n",
        "# ======== Run the same 1D-CNN but only for window size 5 (30 epochs) ========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def run_window(window_size: int):\n",
        "    # --- Rebuild windows for this size (uses your existing build_windows) ---\n",
        "    Xw, yw = build_windows(X, y, window_size)\n",
        "\n",
        "    # Splits (chronological)\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test   = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # Tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32).reshape(-1, 1)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "    # Loaders\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=64, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Model (Conv1d(F->32)->ReLU->Conv1d(32->64)->ReLU->Flatten->Dropout(0.1)->Linear->1)\n",
        "    class CNNRegressor(nn.Module):\n",
        "        def __init__(self, in_ch=NUM_FEATURES, seq_len=window_size):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv1d(in_ch, 32, kernel_size=3, padding=1)\n",
        "            self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "            self.act   = nn.ReLU()\n",
        "            self.drop  = nn.Dropout(0.1)\n",
        "            self.fc    = nn.Linear(64 * seq_len, 1)\n",
        "        def forward(self, x: Tensor) -> Tensor:\n",
        "            x = self.act(self.conv1(x))\n",
        "            x = self.act(self.conv2(x))\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.drop(x)\n",
        "            return self.fc(x)\n",
        "\n",
        "    model = CNNRegressor().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    def eval_mse(dataloader):\n",
        "        model.eval()\n",
        "        tot, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dataloader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "                pred = model(xb)\n",
        "                tot += criterion(pred, yb).item() * xb.size(0)\n",
        "                n += xb.size(0)\n",
        "        return tot / max(n, 1)\n",
        "\n",
        "    # Train exactly 30 epochs\n",
        "    for epoch in range(1, 30 + 1):\n",
        "        model.train()\n",
        "        tr_tot, tr_n = 0.0, 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_tot += loss.item() * xb.size(0)\n",
        "            tr_n   += xb.size(0)\n",
        "\n",
        "        train_mse = tr_tot / tr_n\n",
        "        val_mse   = eval_mse(val_dl)\n",
        "        print(f\"[W={window_size:3d}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # Final test\n",
        "    test_mse = eval_mse(test_dl)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# --- Run only window size = 5 ---\n",
        "results = {}\n",
        "results[5] = run_window(5)\n",
        "\n",
        "print(\"\\nSummary (RMSE):\", {5: f\"{results[5][1]:.4f}\"})\n"
      ],
      "metadata": {
        "id": "g2qw86DVQlHP",
        "outputId": "af1c9606-2958-432f-bcc5-12f076b8de52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                 Open        High         Low       Close  \\\n",
              "Date                                                                        \n",
              "2025-10-16 00:00:00-04:00  248.250000  249.039993  245.130005  247.449997   \n",
              "2025-10-17 00:00:00-04:00  248.020004  253.380005  247.270004  252.289993   \n",
              "2025-10-20 00:00:00-04:00  255.889999  264.380005  255.630005  262.239990   \n",
              "2025-10-21 00:00:00-04:00  261.880005  265.290009  261.829987  262.769989   \n",
              "2025-10-22 00:00:00-04:00  262.649994  262.850006  255.429993  258.450012   \n",
              "\n",
              "                             Volume  Dividends  Stock Splits  \n",
              "Date                                                          \n",
              "2025-10-16 00:00:00-04:00  39777000        0.0           0.0  \n",
              "2025-10-17 00:00:00-04:00  49147000        0.0           0.0  \n",
              "2025-10-20 00:00:00-04:00  90483000        0.0           0.0  \n",
              "2025-10-21 00:00:00-04:00  46695900        0.0           0.0  \n",
              "2025-10-22 00:00:00-04:00  44954300        0.0           0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52c29474-b33e-48e2-a71a-db00a529435c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-10-16 00:00:00-04:00</th>\n",
              "      <td>248.250000</td>\n",
              "      <td>249.039993</td>\n",
              "      <td>245.130005</td>\n",
              "      <td>247.449997</td>\n",
              "      <td>39777000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-17 00:00:00-04:00</th>\n",
              "      <td>248.020004</td>\n",
              "      <td>253.380005</td>\n",
              "      <td>247.270004</td>\n",
              "      <td>252.289993</td>\n",
              "      <td>49147000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-20 00:00:00-04:00</th>\n",
              "      <td>255.889999</td>\n",
              "      <td>264.380005</td>\n",
              "      <td>255.630005</td>\n",
              "      <td>262.239990</td>\n",
              "      <td>90483000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-21 00:00:00-04:00</th>\n",
              "      <td>261.880005</td>\n",
              "      <td>265.290009</td>\n",
              "      <td>261.829987</td>\n",
              "      <td>262.769989</td>\n",
              "      <td>46695900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-22 00:00:00-04:00</th>\n",
              "      <td>262.649994</td>\n",
              "      <td>262.850006</td>\n",
              "      <td>255.429993</td>\n",
              "      <td>258.450012</td>\n",
              "      <td>44954300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52c29474-b33e-48e2-a71a-db00a529435c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52c29474-b33e-48e2-a71a-db00a529435c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52c29474-b33e-48e2-a71a-db00a529435c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f9e9ef60-cac7-4f39-b839-ad0ec3d0eb53\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9e9ef60-cac7-4f39-b839-ad0ec3d0eb53')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f9e9ef60-cac7-4f39-b839-ad0ec3d0eb53 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nSummary (RMSE):\\\", {5: f\\\"{results[5][1]:\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-10-16 00:00:00-04:00\",\n        \"max\": \"2025-10-22 00:00:00-04:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2025-10-17 00:00:00-04:00\",\n          \"2025-10-22 00:00:00-04:00\",\n          \"2025-10-20 00:00:00-04:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.077439357271428,\n        \"min\": 248.02000427246094,\n        \"max\": 262.6499938964844,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          248.02000427246094,\n          262.6499938964844,\n          255.88999938964844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.3163612252542745,\n        \"min\": 249.0399932861328,\n        \"max\": 265.2900085449219,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          253.3800048828125,\n          262.8500061035156,\n          264.3800048828125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.810714131339862,\n        \"min\": 245.1300048828125,\n        \"max\": 261.8299865722656,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          247.27000427246094,\n          255.42999267578125,\n          255.6300048828125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.62554742312618,\n        \"min\": 247.4499969482422,\n        \"max\": 262.7699890136719,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          252.2899932861328,\n          258.45001220703125,\n          262.239990234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20565782,\n        \"min\": 39777000,\n        \"max\": 90483000,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          49147000,\n          44954300,\n          90483000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dividends\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stock Splits\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X: (236, 7) | Size of y: (236,)\n",
            "[W=  5] Epoch 01 | Train MSE: 48818.752111 | Val MSE: 54206.800781\n",
            "[W=  5] Epoch 02 | Train MSE: 48725.828252 | Val MSE: 54122.476562\n",
            "[W=  5] Epoch 03 | Train MSE: 48626.929645 | Val MSE: 54031.406250\n",
            "[W=  5] Epoch 04 | Train MSE: 48517.298670 | Val MSE: 53924.820312\n",
            "[W=  5] Epoch 05 | Train MSE: 48386.315203 | Val MSE: 53791.878906\n",
            "[W=  5] Epoch 06 | Train MSE: 48219.583742 | Val MSE: 53622.097656\n",
            "[W=  5] Epoch 07 | Train MSE: 48005.718159 | Val MSE: 53401.300781\n",
            "[W=  5] Epoch 08 | Train MSE: 47723.877154 | Val MSE: 53118.625000\n",
            "[W=  5] Epoch 09 | Train MSE: 47373.437394 | Val MSE: 52761.332031\n",
            "[W=  5] Epoch 10 | Train MSE: 46917.433974 | Val MSE: 52316.152344\n",
            "[W=  5] Epoch 11 | Train MSE: 46354.761043 | Val MSE: 51765.500000\n",
            "[W=  5] Epoch 12 | Train MSE: 45665.298860 | Val MSE: 51089.875000\n",
            "[W=  5] Epoch 13 | Train MSE: 44817.247530 | Val MSE: 50276.460938\n",
            "[W=  5] Epoch 14 | Train MSE: 43803.561951 | Val MSE: 49305.273438\n",
            "[W=  5] Epoch 15 | Train MSE: 42606.631926 | Val MSE: 48150.824219\n",
            "[W=  5] Epoch 16 | Train MSE: 41183.006715 | Val MSE: 46797.847656\n",
            "[W=  5] Epoch 17 | Train MSE: 39539.888936 | Val MSE: 45228.031250\n",
            "[W=  5] Epoch 18 | Train MSE: 37648.334354 | Val MSE: 43439.960938\n",
            "[W=  5] Epoch 19 | Train MSE: 35534.330870 | Val MSE: 41416.433594\n",
            "[W=  5] Epoch 20 | Train MSE: 33244.462247 | Val MSE: 39146.304688\n",
            "[W=  5] Epoch 21 | Train MSE: 30671.456018 | Val MSE: 36658.289062\n",
            "[W=  5] Epoch 22 | Train MSE: 27979.058710 | Val MSE: 33943.648438\n",
            "[W=  5] Epoch 23 | Train MSE: 25106.065150 | Val MSE: 31056.076172\n",
            "[W=  5] Epoch 24 | Train MSE: 22248.453526 | Val MSE: 28022.806641\n",
            "[W=  5] Epoch 25 | Train MSE: 19297.921199 | Val MSE: 24894.021484\n",
            "[W=  5] Epoch 26 | Train MSE: 16571.700253 | Val MSE: 21742.787109\n",
            "[W=  5] Epoch 27 | Train MSE: 13938.896859 | Val MSE: 18675.251953\n",
            "[W=  5] Epoch 28 | Train MSE: 11657.133404 | Val MSE: 15776.455078\n",
            "[W=  5] Epoch 29 | Train MSE: 9672.669721 | Val MSE: 13133.816406\n",
            "[W=  5] Epoch 30 | Train MSE: 8263.687284 | Val MSE: 10866.714844\n",
            "[W=  5] Test MSE: 4428.813477 | Test RMSE: 66.549331\n",
            "\n",
            "Summary (RMSE): {5: '66.5493'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MfqY1Ez-QK0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xw.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5ftmO_rsk1L",
        "outputId": "874783a7-12ee-43a0-a073-ec50c3312662"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11264, 210)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_windows_stride7(X, y, window_size=7):\n",
        "    xs, ys = [], []\n",
        "    T = len(X)\n",
        "    for start in range(0, T - window_size, window_size):   # stride = 7 days\n",
        "        end = start + window_size\n",
        "        xs.append(X.values[start:end, :])                   # (7, F)\n",
        "        ys.append(y.values[end])                            # next-day Close after the block\n",
        "    Xw = np.stack(xs).reshape(-1, window_size * NUM_FEATURES)  # (N, 7*F)\n",
        "    yw = np.array(ys).reshape(-1, 1)\n",
        "    return Xw, yw\n"
      ],
      "metadata": {
        "id": "INzx4FkF6ZpW"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_windows_stride7(X, y, window_size=8):\n",
        "    xs, ys = [], []\n",
        "    T = len(X)\n",
        "    for start in range(0, T - window_size, window_size):   # stride = 7 days\n",
        "        end = start + window_size\n",
        "        xs.append(X.values[start:end, :])                   # (7, F)\n",
        "        ys.append(y.values[end])                            # next-day Close after the block\n",
        "    Xw = np.stack(xs).reshape(-1, window_size * NUM_FEATURES)  # (N, 7*F)\n",
        "    yw = np.array(ys).reshape(-1, 1)\n",
        "    return Xw, yw\n"
      ],
      "metadata": {
        "id": "h89akZls75VY"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------- Window builders ----------------\n",
        "def build_windows_with_stride(X_df: pd.DataFrame, y_sr: pd.Series, window_size: int, stride: int | None):\n",
        "    \"\"\"\n",
        "    Build windows of length `window_size`.\n",
        "    - If stride is None -> use non-overlapping windows (stride = window_size)\n",
        "    - Else -> advance by `stride` rows each step (e.g., 7 days)\n",
        "    Target = y[end] (the next day after the window)\n",
        "    Returns: Xw (N, window_size*F), yw (N,1)\n",
        "    \"\"\"\n",
        "    F = X_df.shape[1]\n",
        "    Xv = X_df.values\n",
        "    yv = y_sr.values\n",
        "    T  = len(X_df)\n",
        "\n",
        "    step = window_size if stride is None else stride\n",
        "    xs, ys = [], []\n",
        "\n",
        "    # last usable start is strictly < T - window_size (to keep y[end] in-bounds)\n",
        "    for start in range(0, T - window_size, step):\n",
        "        end = start + window_size\n",
        "        if end >= len(yv):  # safety, though T == len(y) here\n",
        "            break\n",
        "        xs.append(Xv[start:end, :])          # (W, F)\n",
        "        ys.append(yv[end])                   # next-day Close after the window\n",
        "    if len(xs) == 0:\n",
        "        return np.empty((0, window_size * F), dtype=np.float32), np.empty((0, 1), dtype=np.float32)\n",
        "\n",
        "    Xw = np.stack(xs).reshape(-1, window_size * F).astype(np.float32)\n",
        "    yw = np.array(ys, dtype=np.float32).reshape(-1, 1)\n",
        "    return Xw, yw\n",
        "\n",
        "# ---------------- Model ----------------\n",
        "class CNNRegressor(nn.Module):\n",
        "    # Conv1d(F->32,k=3)->ReLU->Conv1d(32->64,k=3)->ReLU->Flatten->Dropout(0.1)->Linear->1\n",
        "    def __init__(self, in_ch: int, seq_len: int, dropout_p: float = DROPOUT_P):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_ch, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.act   = nn.ReLU()\n",
        "        self.drop  = nn.Dropout(dropout_p)\n",
        "        self.fc    = nn.Linear(64 * seq_len, 1)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # x: (B, in_ch, seq_len)\n",
        "        x = self.act(self.conv1(x))\n",
        "        x = self.act(self.conv2(x))\n",
        "        x = torch.flatten(x, 1)   # (B, 64*seq_len)\n",
        "        x = self.drop(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# ---------------- Training / Eval ----------------\n",
        "def eval_mse(model, dataloader, window_size: int):\n",
        "    model.eval()\n",
        "    crit = nn.MSELoss()\n",
        "    tot, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in dataloader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)  # (B, F, W)\n",
        "            pred = model(xb)\n",
        "            loss = crit(pred, yb)\n",
        "            tot += loss.item() * xb.size(0)\n",
        "            n   += xb.size(0)\n",
        "    return tot / max(n, 1)\n",
        "\n",
        "def run_window(window_size: int, stride_days: int | None):\n",
        "    # 1) Build windows with the chosen stride\n",
        "    Xw, yw = build_windows_with_stride(X, y, window_size, stride_days)\n",
        "    if len(Xw) == 0:\n",
        "        print(f\"[W={window_size}] No samples produced. Try a smaller window or different stride.\")\n",
        "        return math.inf, math.inf\n",
        "\n",
        "    # 2) Chronological split 80/10/10 via two splits\n",
        "    X_train, X_tmp, y_train, y_tmp = train_test_split(Xw, yw, test_size=0.2, shuffle=False)\n",
        "    X_val,   X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, shuffle=False)\n",
        "\n",
        "    # 3) Scale (fit on train only)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val   = scaler.transform(X_val)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    # 4) Tensors & loaders\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "    X_val   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "    y_val   = torch.tensor(y_val,   dtype=torch.float32)\n",
        "    X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "    y_test  = torch.tensor(y_test,  dtype=torch.float32)\n",
        "\n",
        "    train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH, shuffle=True,  drop_last=False)\n",
        "    val_dl   = DataLoader(TensorDataset(X_val,   y_val),   batch_size=BATCH, shuffle=False, drop_last=False)\n",
        "    test_dl  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=BATCH, shuffle=False, drop_last=False)\n",
        "\n",
        "    # 5) Model / optimiser\n",
        "    model = CNNRegressor(in_ch=NUM_FEATURES, seq_len=window_size).to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    crit = nn.MSELoss()\n",
        "\n",
        "    # 6) Train exactly 30 epochs\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        tr_sum = tr_n = 0\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            xb = xb.reshape(-1, window_size, NUM_FEATURES).permute(0, 2, 1)  # (B, F, W)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            pred = model(xb)\n",
        "            loss = crit(pred, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_sum += loss.item() * xb.size(0)\n",
        "            tr_n   += xb.size(0)\n",
        "\n",
        "        train_mse = tr_sum / tr_n\n",
        "        val_mse   = eval_mse(model, val_dl, window_size)\n",
        "        lbl_stride = f\"stride={window_size}\" if stride_days is None else f\"stride={stride_days}\"\n",
        "        print(f\"[W={window_size:3d}, {lbl_stride}] Epoch {epoch:02d} | Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
        "\n",
        "    # 7) Final test\n",
        "    test_mse  = eval_mse(model, test_dl, window_size)\n",
        "    test_rmse = float(np.sqrt(test_mse))\n",
        "    print(f\"[W={window_size:3d}] Test MSE: {test_mse:.6f} | Test RMSE: {test_rmse:.6f}\")\n",
        "    return test_mse, test_rmse\n",
        "\n",
        "# ---------------- Run all configs ----------------\n",
        "results = {}\n",
        "for W in WINDOWS:\n",
        "    results[W] = run_window(W, stride_days=DATA_STRIDE)\n",
        "\n",
        "print(\"\\nSummary (RMSE):\", {W: f\"{rmse:.4f}\" for W, (_, rmse) in results.items()})\n",
        "\n",
        "# ---------------- Optional: quick prediction plot for the last run ----------------\n",
        "# (Uncomment to visualise)\n",
        "# last_W = WINDOWS[-1]\n",
        "# _ = run_window(last_W, stride_days=DATA_STRIDE)  # re-run to get last loaders/model if you adapt to return preds\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfvew2J7BwCI",
        "outputId": "7efe62b7-0723-4b70-a37a-c4399a24aaf6"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W=  5, stride=7] Epoch 01 | Train MSE: 54.733826 | Val MSE: 1857.357895\n",
            "[W=  5, stride=7] Epoch 02 | Train MSE: 11.100988 | Val MSE: 1407.070679\n",
            "[W=  5, stride=7] Epoch 03 | Train MSE: 2.697051 | Val MSE: 199.583467\n",
            "[W=  5, stride=7] Epoch 04 | Train MSE: 1.455250 | Val MSE: 306.148811\n",
            "[W=  5, stride=7] Epoch 05 | Train MSE: 0.996052 | Val MSE: 110.440145\n",
            "[W=  5, stride=7] Epoch 06 | Train MSE: 0.764832 | Val MSE: 98.126183\n",
            "[W=  5, stride=7] Epoch 07 | Train MSE: 0.505385 | Val MSE: 20.393007\n",
            "[W=  5, stride=7] Epoch 08 | Train MSE: 0.376464 | Val MSE: 13.836943\n",
            "[W=  5, stride=7] Epoch 09 | Train MSE: 0.312149 | Val MSE: 18.930426\n",
            "[W=  5, stride=7] Epoch 10 | Train MSE: 0.249271 | Val MSE: 14.193375\n",
            "[W=  5, stride=7] Epoch 11 | Train MSE: 0.237172 | Val MSE: 24.860609\n",
            "[W=  5, stride=7] Epoch 12 | Train MSE: 0.174101 | Val MSE: 18.012025\n",
            "[W=  5, stride=7] Epoch 13 | Train MSE: 0.177028 | Val MSE: 11.259308\n",
            "[W=  5, stride=7] Epoch 14 | Train MSE: 0.167008 | Val MSE: 14.139525\n",
            "[W=  5, stride=7] Epoch 15 | Train MSE: 0.157204 | Val MSE: 13.139627\n",
            "[W=  5, stride=7] Epoch 16 | Train MSE: 0.161603 | Val MSE: 12.665968\n",
            "[W=  5, stride=7] Epoch 17 | Train MSE: 0.143146 | Val MSE: 11.148112\n",
            "[W=  5, stride=7] Epoch 18 | Train MSE: 0.144128 | Val MSE: 11.144629\n",
            "[W=  5, stride=7] Epoch 19 | Train MSE: 0.115982 | Val MSE: 11.873780\n",
            "[W=  5, stride=7] Epoch 20 | Train MSE: 0.142343 | Val MSE: 12.394790\n",
            "[W=  5, stride=7] Epoch 21 | Train MSE: 0.164820 | Val MSE: 11.322884\n",
            "[W=  5, stride=7] Epoch 22 | Train MSE: 0.130755 | Val MSE: 11.809209\n",
            "[W=  5, stride=7] Epoch 23 | Train MSE: 0.103658 | Val MSE: 11.888634\n",
            "[W=  5, stride=7] Epoch 24 | Train MSE: 0.131407 | Val MSE: 15.745957\n",
            "[W=  5, stride=7] Epoch 25 | Train MSE: 0.114532 | Val MSE: 11.431676\n",
            "[W=  5, stride=7] Epoch 26 | Train MSE: 0.135441 | Val MSE: 11.833110\n",
            "[W=  5, stride=7] Epoch 27 | Train MSE: 0.113818 | Val MSE: 13.706689\n",
            "[W=  5, stride=7] Epoch 28 | Train MSE: 0.120669 | Val MSE: 10.848899\n",
            "[W=  5, stride=7] Epoch 29 | Train MSE: 0.123627 | Val MSE: 12.594352\n",
            "[W=  5, stride=7] Epoch 30 | Train MSE: 0.131063 | Val MSE: 10.370989\n",
            "[W=  5] Test MSE: 62.269482 | Test RMSE: 7.891101\n",
            "[W= 20, stride=7] Epoch 01 | Train MSE: 33.642978 | Val MSE: 1737.870854\n",
            "[W= 20, stride=7] Epoch 02 | Train MSE: 5.435168 | Val MSE: 235.458766\n",
            "[W= 20, stride=7] Epoch 03 | Train MSE: 1.957016 | Val MSE: 179.385293\n",
            "[W= 20, stride=7] Epoch 04 | Train MSE: 1.064489 | Val MSE: 142.489386\n",
            "[W= 20, stride=7] Epoch 05 | Train MSE: 0.604311 | Val MSE: 25.495667\n",
            "[W= 20, stride=7] Epoch 06 | Train MSE: 0.367747 | Val MSE: 32.500333\n",
            "[W= 20, stride=7] Epoch 07 | Train MSE: 0.263640 | Val MSE: 15.408930\n",
            "[W= 20, stride=7] Epoch 08 | Train MSE: 0.190168 | Val MSE: 13.887288\n",
            "[W= 20, stride=7] Epoch 09 | Train MSE: 0.140547 | Val MSE: 17.322965\n",
            "[W= 20, stride=7] Epoch 10 | Train MSE: 0.122055 | Val MSE: 13.810271\n",
            "[W= 20, stride=7] Epoch 11 | Train MSE: 0.131660 | Val MSE: 13.901886\n",
            "[W= 20, stride=7] Epoch 12 | Train MSE: 0.135047 | Val MSE: 14.919073\n",
            "[W= 20, stride=7] Epoch 13 | Train MSE: 0.142213 | Val MSE: 25.944553\n",
            "[W= 20, stride=7] Epoch 14 | Train MSE: 0.109388 | Val MSE: 14.236712\n",
            "[W= 20, stride=7] Epoch 15 | Train MSE: 0.105848 | Val MSE: 14.469961\n",
            "[W= 20, stride=7] Epoch 16 | Train MSE: 0.090815 | Val MSE: 14.066357\n",
            "[W= 20, stride=7] Epoch 17 | Train MSE: 0.092581 | Val MSE: 13.544217\n",
            "[W= 20, stride=7] Epoch 18 | Train MSE: 0.085316 | Val MSE: 35.007800\n",
            "[W= 20, stride=7] Epoch 19 | Train MSE: 0.141740 | Val MSE: 13.292134\n",
            "[W= 20, stride=7] Epoch 20 | Train MSE: 0.104583 | Val MSE: 16.996508\n",
            "[W= 20, stride=7] Epoch 21 | Train MSE: 0.105504 | Val MSE: 17.471570\n",
            "[W= 20, stride=7] Epoch 22 | Train MSE: 0.092340 | Val MSE: 24.306015\n",
            "[W= 20, stride=7] Epoch 23 | Train MSE: 0.219002 | Val MSE: 17.321956\n",
            "[W= 20, stride=7] Epoch 24 | Train MSE: 0.148310 | Val MSE: 15.196385\n",
            "[W= 20, stride=7] Epoch 25 | Train MSE: 0.090477 | Val MSE: 20.183220\n",
            "[W= 20, stride=7] Epoch 26 | Train MSE: 0.081069 | Val MSE: 15.816327\n",
            "[W= 20, stride=7] Epoch 27 | Train MSE: 0.083169 | Val MSE: 14.016781\n",
            "[W= 20, stride=7] Epoch 28 | Train MSE: 0.080704 | Val MSE: 14.915311\n",
            "[W= 20, stride=7] Epoch 29 | Train MSE: 0.108190 | Val MSE: 19.809284\n",
            "[W= 20, stride=7] Epoch 30 | Train MSE: 0.071983 | Val MSE: 16.051844\n",
            "[W= 20] Test MSE: 79.655202 | Test RMSE: 8.924976\n",
            "[W=100, stride=7] Epoch 01 | Train MSE: 18.694037 | Val MSE: 92.939520\n",
            "[W=100, stride=7] Epoch 02 | Train MSE: 2.308000 | Val MSE: 64.706559\n",
            "[W=100, stride=7] Epoch 03 | Train MSE: 1.152543 | Val MSE: 56.301589\n",
            "[W=100, stride=7] Epoch 04 | Train MSE: 0.788118 | Val MSE: 44.430683\n",
            "[W=100, stride=7] Epoch 05 | Train MSE: 0.594593 | Val MSE: 42.967665\n",
            "[W=100, stride=7] Epoch 06 | Train MSE: 0.381389 | Val MSE: 101.203402\n",
            "[W=100, stride=7] Epoch 07 | Train MSE: 0.310198 | Val MSE: 145.213647\n",
            "[W=100, stride=7] Epoch 08 | Train MSE: 0.304032 | Val MSE: 99.306089\n",
            "[W=100, stride=7] Epoch 09 | Train MSE: 0.227624 | Val MSE: 85.446007\n",
            "[W=100, stride=7] Epoch 10 | Train MSE: 0.201779 | Val MSE: 162.321899\n",
            "[W=100, stride=7] Epoch 11 | Train MSE: 0.199321 | Val MSE: 111.984135\n",
            "[W=100, stride=7] Epoch 12 | Train MSE: 0.169231 | Val MSE: 89.105356\n",
            "[W=100, stride=7] Epoch 13 | Train MSE: 0.127749 | Val MSE: 105.010653\n",
            "[W=100, stride=7] Epoch 14 | Train MSE: 0.115624 | Val MSE: 69.269654\n",
            "[W=100, stride=7] Epoch 15 | Train MSE: 0.100445 | Val MSE: 51.305872\n",
            "[W=100, stride=7] Epoch 16 | Train MSE: 0.100858 | Val MSE: 60.702048\n",
            "[W=100, stride=7] Epoch 17 | Train MSE: 0.106735 | Val MSE: 131.988052\n",
            "[W=100, stride=7] Epoch 18 | Train MSE: 0.095754 | Val MSE: 107.436299\n",
            "[W=100, stride=7] Epoch 19 | Train MSE: 0.082776 | Val MSE: 84.470908\n",
            "[W=100, stride=7] Epoch 20 | Train MSE: 0.071086 | Val MSE: 74.771747\n",
            "[W=100, stride=7] Epoch 21 | Train MSE: 0.065866 | Val MSE: 78.421136\n",
            "[W=100, stride=7] Epoch 22 | Train MSE: 0.061688 | Val MSE: 54.814308\n",
            "[W=100, stride=7] Epoch 23 | Train MSE: 0.052121 | Val MSE: 63.660270\n",
            "[W=100, stride=7] Epoch 24 | Train MSE: 0.049656 | Val MSE: 54.753489\n",
            "[W=100, stride=7] Epoch 25 | Train MSE: 0.045636 | Val MSE: 70.997045\n",
            "[W=100, stride=7] Epoch 26 | Train MSE: 0.048937 | Val MSE: 51.748516\n",
            "[W=100, stride=7] Epoch 27 | Train MSE: 0.048961 | Val MSE: 72.651852\n",
            "[W=100, stride=7] Epoch 28 | Train MSE: 0.048329 | Val MSE: 77.037515\n",
            "[W=100, stride=7] Epoch 29 | Train MSE: 0.058807 | Val MSE: 32.585282\n",
            "[W=100, stride=7] Epoch 30 | Train MSE: 0.078592 | Val MSE: 62.847952\n",
            "[W=100] Test MSE: 161.276428 | Test RMSE: 12.699466\n",
            "\n",
            "Summary (RMSE): {5: '7.8911', 20: '8.9250', 100: '12.6995'}\n"
          ]
        }
      ]
    }
  ]
}